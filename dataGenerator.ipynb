{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle as pk\n",
    "import cv2\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import SimpleITK as sitk\n",
    "import nibabel as nb\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "import time\n",
    "from albumentations.augmentations.transforms import ElasticTransform\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "rootFolder = 'C:\\\\Users\\\\sm5797\\\\Documents\\\\CochleaRIT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineMasks(ST, SM, SV):\n",
    "    STmask = np.where(ST>10., 1., 0.)\n",
    "    SMmask = np.where(SM>10., 2., 0.)\n",
    "    SVmask = np.where(SV>10., 3., 0.)\n",
    "    \n",
    "    combineTemp = STmask + SMmask\n",
    "    combineTemp = np.where(combineTemp==3, 1, combineTemp)\n",
    "    \n",
    "    finMask = combineTemp + SVmask\n",
    "    finMask = np.where(finMask==4, 1, finMask)\n",
    "    finMask = np.where(finMask==5, 2, finMask)\n",
    "    \n",
    "    return finMask\n",
    "\n",
    "def rszForModel(vol):\n",
    "    rszScan = []\n",
    "    finScan = []\n",
    "    t1 = time.time()\n",
    "    for i in range(vol.shape[2]):\n",
    "        slc = vol[:,:,i]\n",
    "        rszSlc = cv2.resize(slc, (256,256))\n",
    "        rszScan.append(rszSlc)\n",
    "    rszScan = np.array(rszScan)\n",
    "        \n",
    "    for j in range(rszScan.shape[2]):\n",
    "        slc2 = rszScan[:,:,j]\n",
    "        rszSlc2 = cv2.resize(slc2, (256,256))\n",
    "        finScan.append(rszSlc2)\n",
    "    finScan = np.array(finScan)\n",
    "    t2 = time.time() - t1\n",
    "    print('time taken to do interpolation: ',t2)\n",
    "    \n",
    "    '''\n",
    "    volSz = vol.shape\n",
    "    scale = tuple([256/x for x in volSz])\n",
    "    t1 = time.time()\n",
    "    rszVol = zoom(vol, zoom=scale)\n",
    "    t2 = time.time() - t1\n",
    "    print('time taken to do interpolation: ',t2)\n",
    "    '''\n",
    "    \n",
    "    return finScan.transpose((2,0,1)) #rszVol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CochleaRIT(Dataset):\n",
    "\n",
    "    def __init__(self, dataPartition, dataPath, transform=None):\n",
    "    #def __init__(self, dataPath, transform=None):\n",
    "        self.dataPath = os.path.join(dataPath, dataPartition)\n",
    "        self.dataList = []\n",
    "        for foldr in os.listdir(self.dataPath):\n",
    "            self.dataList.append(os.path.join(self.dataPath, foldr))\n",
    "        self.dataPartition = dataPartition\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataList)\n",
    "\n",
    "    def __getitem__(self, img_id):\n",
    "        #imgID = self.dataList[img_id]\n",
    "        imagePath = os.path.join(self.dataList[img_id], 'ear.nii')\n",
    "        STPath = os.path.join(self.dataList[img_id], 'ST_labelmap.nii')\n",
    "        SMPath = os.path.join(self.dataList[img_id], 'SM_labelmap.nii')\n",
    "        SVPath = os.path.join(self.dataList[img_id], 'SV_labelmap.nii')\n",
    "        \n",
    "        img = nb.load(imagePath)\n",
    "        scan = img.get_fdata()\n",
    "        scan = rszForModel(scan)\n",
    "        scan = scan.astype(np.uint8)\n",
    "        \n",
    "        lm1 = nb.load(STPath)\n",
    "        lm2 = nb.load(SMPath)\n",
    "        lm3 = nb.load(SVPath)\n",
    "        \n",
    "        ST_temp = lm1.get_fdata()\n",
    "        SM_temp = lm2.get_fdata()\n",
    "        SV_temp = lm3.get_fdata()\n",
    "        \n",
    "        ST_temp = rszForModel(ST_temp)\n",
    "        SM_temp = rszForModel(SM_temp)\n",
    "        SV_temp = rszForModel(SV_temp)\n",
    "        \n",
    "        finalMask = combineMasks(ST_temp, SM_temp, SV_temp).astype(np.uint8)\n",
    "        scan = np.divide(scan, 255.)\n",
    "\n",
    "        dataDict = {'scan': scan, 'mask': finalMask}\n",
    "\n",
    "        if self.transform:\n",
    "            dataDict = self.transform(dataDict)\n",
    "\n",
    "        return dataDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Augmentations(object):\n",
    "    def __init__(self, dataPartition, enable=False):\n",
    "        self.dataPartition = dataPartition\n",
    "        self.enable = enable\n",
    "        \n",
    "    def __call__(self, dataDict):\n",
    "        if self.enable:\n",
    "            scan_, mask_ = dataDict['scan'], dataDict['mask']\n",
    "            alpha_ = np.random.randint(25,75)\n",
    "            tx = ElasticTransform(p=1, alpha=alpha_, sigma=6, alpha_affine=3)\n",
    "            #tx = ElasticTransform(p=1, alpha=100, sigma=6, alpha_affine=3, border_mode=cv2.BORDER_CONSTANT, value=0, mask_value=0)\n",
    "            \n",
    "            txdDataSample = tx(image=scan_, mask=mask_)\n",
    "            \n",
    "            elasticScan = txdDataSample['image']\n",
    "            elasticMask = txdDataSample['mask']\n",
    "            elasticMask = (np.arange(4) == elasticMask[..., None]).astype(np.uint8).transpose((3,0,1,2))\n",
    "            print(elasticMask.shape)\n",
    "\n",
    "            elasticScan = elasticScan[np.newaxis, ...]\n",
    "            #elasticMask = elasticMask[np.newaxis, ...]\n",
    "            dataDict = {'scan': elasticScan, 'mask': elasticMask}\n",
    "\n",
    "        else:\n",
    "            scan_, mask_ = dataDict['scan'], dataDict['mask']\n",
    "            \n",
    "            mask_ = (np.arange(4) == mask_[..., None]).astype(np.uint8).transpose((3,0,1,2))\n",
    "            noTxMask = mask_\n",
    "            noTxScan = scan_[np.newaxis, ...]\n",
    "            #noTxMask = mask_[np.newaxis, ...]\n",
    "            dataDict = {'scan': noTxScan, 'mask': noTxMask}\n",
    "\n",
    "        return dataDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        scan_, mask_ = sample['scan'], sample['mask']\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x D x C\n",
    "        # torch image: C x H x W x D\n",
    "        scan_ = scan_.transpose((0, 3, 1, 2))\n",
    "        #mask_ = mask_.transpose((0, 3, 1, 2))\n",
    "        tempImg = torch.from_numpy(scan_)\n",
    "        tempMsk = torch.from_numpy(mask_)\n",
    "\n",
    "        tempImg = tempImg.type(torch.FloatTensor)\n",
    "        tempMsk = tempMsk.type(torch.FloatTensor)\n",
    "        return {'scan': tempImg, 'mask': tempMsk}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train1 = CochleaRIT('train', rootFolder, transform=transforms.Compose([Augmentations('train',True), ToTensor()]))\n",
    "#train2 = CochleaRIT('train', rootFolder, transform=transforms.Compose([Augmentations('train',True)]))\n",
    "#train = CochleaRIT('train', rootFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time taken to do interpolation:  0.3248598575592041\n",
      "time taken to do interpolation:  0.32385730743408203\n",
      "time taken to do interpolation:  0.32937192916870117\n",
      "time taken to do interpolation:  0.3253607749938965\n",
      "(4, 256, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "im = train1.__getitem__(0)\n",
    "#im2 = train2.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 256, 256])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1dc0cfdbe80>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(im['scan'].shape)\n",
    "plt.imshow(im['mask'][1,:,:,200].squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im1['mask'].squeeze()[:,:,200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(im2['mask'].squeeze()[:,:,200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py36)",
   "language": "python",
   "name": "py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
